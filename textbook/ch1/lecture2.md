Here‚Äôs Lecture 2 for CIDS 161, formatted for clarity and structure while maintaining all key details. Let me know if you‚Äôd like any further refinements!

CIDS 161: Introduction to Computing

Lecture 2 - January 29, 2025

Introduction

Welcome back to CIDS 161! Today, we‚Äôre diving into the foundations of computing‚Äîwhat computers are, what programs are, and how computing has evolved throughout history. Before we begin, just a quick note about our textbook:
	‚Ä¢	Textbook (Optional): Introduction to Programming Using Python by Y. Daniel Liang
	‚Ä¢	You do not need to purchase this book, but I will reference it throughout the course.

Now, let‚Äôs start with a fundamental question:

What is a Computer?

To understand programming, we must first define what a computer actually is.

Think about it: almost everyone here has a computer‚Äîwhether it‚Äôs a laptop, desktop, or even your smartphone (which is essentially a powerful computer in your pocket).

But what exactly is a computer? A computer is a device capable of processing information, following instructions, and performing computations.

To understand computers better, let‚Äôs define another key term:

What is a Program?

A program is a set of instructions that a computer follows to perform a task.

Here are some student-suggested definitions of a program:
	1.	‚ÄúA line of code that does something.‚Äù
	2.	‚ÄúA series of tasks for a computer to perform.‚Äù

These definitions are close! Let‚Äôs refine them:

A computer program is software that contains instructions that tell a computer what to do.

Now, we‚Äôve introduced another key term: software.

Software vs. Hardware
	‚Ä¢	Hardware = The physical components of a computer (e.g., processor, memory, keyboard).
	‚Ä¢	Software = The digital instructions that tell the hardware what to do.

Analogy:
	‚Ä¢	Hardware is like a chef in a kitchen.
	‚Ä¢	Software is like a recipe‚Äîit provides instructions for the chef to follow.

Now that we understand what computers and programs are, let‚Äôs look at the history of computing and how it has evolved over time.

A Brief History of Computing

Computers Before Machines: The Human Computers

Did you know that before electronic computers, the word ‚Äúcomputer‚Äù referred to a person?
	‚Ä¢	In the 1940s, human ‚Äúcomputers‚Äù (often women) were hired to perform complex mathematical calculations, particularly during World War II.

The Role of Computing in World War II

Computing advanced significantly due to codebreaking efforts during WWII.
	‚Ä¢	The Enigma Machine was a German encryption device used to encode military communications.

<img src="/Users/trevortomesh/Desktop/SP2025/UWRF/CIDS161-Sp25/textbook/assets/images/Enigma_(crittografia)_-_Museo_scienza_e_tecnologia_Milano.jpg" alt="drawing" width="600"/>

‚Äã	

‚Ä¢	The Allies needed to crack the code to predict German movements.

Alan Turing and the Bombe Machine

One of the most famous figures in computing history, Alan Turing, helped develop a device called the Bombe, which was used to break Enigma‚Äôs encryption.

<img src="/Users/trevortomesh/Desktop/SP2025/UWRF/CIDS161-Sp25/textbook/assets/images/bombe.jpg" alt="drawing" width="500"/>

‚Äã	‚Ä¢	Turing‚Äôs work shortened WWII by an estimated 2-5 years and saved millions of lives.
‚Äã	‚Ä¢	This was a major step toward modern computing.

The Evolution of Computing Devices

1. Early Computational Tools

Before modern computers, humans used various mechanical devices for calculations:

Tally Sticks (~50,000‚Äì12,000 BCE)
	‚Ä¢	One of the earliest mathematical tools, used for counting and record-keeping.
	‚Ä¢	Example: The Ishango Bone (Democratic Republic of Congo), possibly the first counting device.

<img src="/Users/trevortomesh/Desktop/SP2025/UWRF/CIDS161-Sp25/textbook/assets/images/bone.jpg" alt="drawing" width="200"/>

Abacus (~2,000 BCE)
	‚Ä¢	An early calculating tool used to perform addition and subtraction quickly.
	‚Ä¢	Still used today in some regions!

<img src="/Users/trevortomesh/Desktop/SP2025/UWRF/CIDS161-Sp25/textbook/assets/images/abacus.jpg" width="500"/>

Calculi (Counting Stones) (~3,400 BCE - 3,000 BCE)
	‚Ä¢	Used in ancient Mesopotamia to track trade transactions.
	‚Ä¢	Clay tokens represented quantities of goods and were stored in sealed clay balls to prevent fraud.

<img src="/Users/trevortomesh/Desktop/SP2025/UWRF/CIDS161-Sp25/textbook/assets/images/calculi.jpg" width="500"/>

2. Mechanical Computers

As civilizations advanced, so did computing devices:

The Antikythera Mechanism (~100 BCE)
	‚Ä¢	An ancient Greek mechanical computer used to predict astronomical events.
	‚Ä¢	Considered the first analog computer.
<img src="/Users/trevortomesh/Desktop/SP2025/UWRF/CIDS161-Sp25/textbook/assets/images/am.jpg" width="500"/>

Astrolabes (~150 BCE - 1600s CE)
	‚Ä¢	Used by sailors to navigate using the stars.

<img src="/Users/trevortomesh/Desktop/SP2025/UWRF/CIDS161-Sp25/textbook/assets/images/astrolabe.jpg" width="500"/>

Slide Rule (1620s - 1970s)
	‚Ä¢	A mechanical tool used for multiplication, division, logarithms, and trigonometry.
	‚Ä¢	Used by engineers and scientists before calculators existed!

<img src="/Users/trevortomesh/Desktop/SP2025/UWRF/CIDS161-Sp25/textbook/assets/images/sliderule.jpg" width="500"/>

3. The First Programmable Machines

The Jacquard Loom (1804)
	‚Ä¢	One of the first programmable machines, used for weaving textiles.
	‚Ä¢	Used punch cards to store and execute patterns.

<img src="/Users/trevortomesh/Desktop/SP2025/UWRF/CIDS161-Sp25/textbook/assets/images/jl.jpg" width="300"/>

Punch Cards (~1800s - 1980s)
	‚Ä¢	Used to store data and program early computers.
	‚Ä¢	Found in early voting systems, census data collection, and IBM mainframes.

<img src="/Users/trevortomesh/Desktop/SP2025/UWRF/CIDS161-Sp25/textbook/assets/images/pc.jpg" width="500"/>

Charles Babbage‚Äôs Analytical Engine (~1837)
	‚Ä¢	Considered the first general-purpose programmable computer.
	‚Ä¢	Designed but never built due to lack of funding.
	‚Ä¢	Introduced ideas like memory storage and an arithmetic unit (which modern computers still use).

<img src="/Users/trevortomesh/Desktop/SP2025/UWRF/CIDS161-Sp25/textbook/assets/images/cb.jpg" width="500"/>

Computing in the 20th Century

Alan Turing and the Concept of Modern Computing
	‚Ä¢	Turing introduced the idea of a universal machine that could simulate any other machine (Turing Machine).
	‚Ä¢	His work laid the foundation for modern computers and artificial intelligence.

Post-WWII Computing Advancements

After WWII, computing evolved rapidly:
	1.	1940s-1950s: The first electronic computers (e.g., ENIAC, UNIVAC).
	2.	1950s-1970s: The rise of mainframe computers and early programming languages (e.g., FORTRAN, COBOL).
	3.	1980s-1990s: The personal computer revolution (Apple, IBM, Microsoft).
	4.	2000s-Present: The development of smartphones, AI, cloud computing, and quantum computing.

Summary
	‚Ä¢	Computers were originally human mathematicians before machines took over.
	‚Ä¢	Early computing devices (tally sticks, abacuses, punch cards) helped develop modern computing.
	‚Ä¢	The Enigma Machine & Alan Turing‚Äôs Bombe played a major role in WWII and early computer science.
	‚Ä¢	Mechanical and early electronic computers paved the way for the digital revolution.

Practice Questions
	1.	What is the difference between software and hardware? Provide an analogy to explain your answer.
	2.	Describe the role of Alan Turing in computing history. How did his work impact WWII?
	3.	Explain how early computing devices (e.g., tally sticks, abacuses, or the Antikythera Mechanism) helped shape modern computers.

Next Lecture Preview

In our next session, we‚Äôll discuss:
	‚Ä¢	The rise of modern computing
	‚Ä¢	The difference between computers and programming languages
	‚Ä¢	What it means for a computer to be Turing complete

See you on Friday! üöÄ